## 1.1 请说明什么是传统的消息传递方法？

**传统的消息传递方法包括两种**：
**排队：在队列中，一组用户可以从服务器中读取消息，每条消息都发送给其中一个人**。
**发布-订阅：在这个模型中，消息被广播给所有的用户**。 

## 1.2 请说明 Kafka 相对于传统的消息传递方法有什么优势？ 

（1）**高性能：单一的 Kafka 代理可以处理成千上万的客户端，每秒处理数兆字节的读写操作，Kafka 性能远超过传统的 ActiveMQ、RabbitMQ 等，而且 Kafka 支持 Batch 操作**；
（2）**可扩展：Kafka 集群可以透明的扩展，增加新的服务器进集群**；
（3）**容错性：Kafka 每个Partition 数据会复制到几台服务器，当某个Broker 失效时，Zookeeper将通知生产者和消费者从而使用其他的 Broker**； 

## 1.3 在 Kafka 中 broker 的意义是什么？

​	**在 Kafka 集群中，broker 指 Kafka 服务器**。

## 1.4 Kafka 中 的 ZooKeeper 是 什 么 ？ Kafka 是 否 可 以 脱 离ZooKeeper 独立运行？ 

​	**Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用**。

**不可以，不可能越过 Zookeeper 直接联系 Kafka broker，一旦 Zookeeper 停止工作，它就不能服务客户端请求**。**Zookeeper 主要用于在集群中不同节点之间进行通信，在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取，除此之外，它还执行其他活动**，如: **leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等**。

## 1.5 解释一下，在数据制作过程中，你如何能从 Kafka 得到准确的信息？ 

​	在数据中，**为了精确地获得 Kafka 的消息，你必须遵循两件事: 在数据消耗期间避免重复，在数据生产过程中避免重复**。
​	这里有两种方法，可以在数据生成时准确地获得一个语义:每个分区使用一个单独的写入器，每当你发现一个网络错误，检查该分区中的最后一条消息，以查看您的最后一次写入是否成功在消息中包含一个主键(UUID 或其他)，并在用户中进行反复制

## 1.6 Kafka 为什么需要复制？

​	**Kafka 的信息复制确保了任何已发布的消息不会丢失，并且可以在机器错误、程序错误或更常见些的软件升级中使用**。 

## 1.7 如何保证 Kafka 的消息有序？

​	**Kafka 对于消息的重复、丢失、错误以及顺序没有严格的要求**。Kafka 只能保证一个partition 中的消息被某个consumer 消费时是顺序的，事实上，从Topic角度来说，当有多个 partition 时，消息仍然不是全局有序的。 

## 1.8 kafka 数据丢失问题,及如何保证？

​	**kafka的ack机制：在kafka发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到**。 

### 1.8.1 数据丢失:

​	**acks=1 的时候(只保证写入 leader 成功)，如果刚好 leader 挂了。数据会丢失**。
​	**acks=0 的时候，使用异步模式的时候，该模式下 kafka 无法保证消息，有可能会丢**

### 1.8.2 brocker 如何保证不丢失

acks=all : 所有副本都写入成功并确认。
retries = 一个合理值。
min.insync.replicas=2 消息至少要被写入到这么多副本才算成功。
unclean.leader.election.enable=false 关闭 unclean leader 选举，即不允许非 ISR 中的副本被
选举为 leader，以避免数据丢失。

### 1.8.3 Consumer 如何保证不丢失

如果在消息处理完成前就提交了 offset，那么就有可能造成数据的丢失。
enable.auto.commit=false 关闭自动提交 offset。处理完数据之后手动提交。 

## 1.9 kafka 的消费者方式？

**consumer 采用 pull（拉）模式从 broker 中读取数据**。
**push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的**。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。

​	**对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义**。
​	**pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞**。

## 1.10.Kafka的设计是怎么样的呢？

​	**Kafka将消息以topic为单位进行归纳，将向Kafka topic发布消息的程序成为producers**，**将预订topics并消费消息的程序成为consumer，Kafka以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个broker，producers通过网络将消息发送到Kafka集群，集群向消费者提供消息**

## 1.11 Kafka判断一个节点是否还活着有那两个条件？

（1）**节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接**
（2）**如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久**

## 1.12 producer是否直接将数据发送到broker的leader(主节点)？

​	producer直接将数据发送到broker的leader(主节点)，不需要在多个节点进行分发，为了帮助producer做到这点，所有的Kafka节点都可以及时的告知:哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了

## 1.13 Kafa consumer是否可以消费指定分区消息？

​	Kafa consumer消费消息时，向broker发出"fetch"请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，consumer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的

## 1.14 Kafka高效文件存储设计特点：

（1）**Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用**。

（2）**通过索引信息可以快速定位message和确定response的最大大小**。

（3）**通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作**。

（4）**通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小**。

## 1.15 Kafka 与传统消息系统之间有三个关键区别

（1）**Kafka 持久化日志，这些日志可以被重复读取和无限期保留**
（2）**Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性**
（3）**Kafka 支持实时的流式处理**

## 1.17 partition的数据如何保存到硬盘?

​	**topic中的多个partition以文件夹的形式保存到broker，每个分区序号从0递增，且消息有序**。Partition文件下有多个segment（xxx.index，xxx.log），segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为1g，如果大小大于1g时，会滚动一个新的segment并且以上一个segment最后一条消息的偏移量命名。

## 1.18 kafka的ack机制?

**request.required.acks有三个值 0 1 -1**
**0：生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢数据**
**1：服务端会等待ack值 leader副本确认接收到消息后发送ack但是如果leader挂掉后他不确保是否复制完成新leader也会导致数据丢失**
**-1：同样在1的基础上 服务端会等所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失**

## 1.19 Kafka的消费者如何消费数据?

​	**消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置，等到下次消费时，他会接着上次位置继续消费**

## 1.20 kafaka生产数据时数据的分组策略?

​	生产者决定数据产生到集群的哪个partition中每一条消息都是以（key，value）格式Key是由生产者发送数据传入。所以生产者（key）决定了数据产生到集群的哪个partition

原文链接：https://blog.csdn.net/shujuelin/java/article/details/89020423